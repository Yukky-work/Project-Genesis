import os
import requests
import streamlit as st
import google.generativeai as genai
from PIL import Image
from dotenv import load_dotenv
from streamlit_mic_recorder import mic_recorder # â˜…éŒ²éŸ³ç”¨(æ–‡å­—å¤‰æ›ãªã—)

# ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼ãƒ‡ãƒ¼ã‚¿
from characters import DATA as CHARACTERS

# --- 1. è¨­å®š ---
load_dotenv()
API_KEY = os.getenv("GEMINI_API_KEY")
if not API_KEY:
    st.error("APIã‚­ãƒ¼è¨­å®šã‚¨ãƒ©ãƒ¼")
    st.stop()

genai.configure(api_key=API_KEY)
MODEL_NAME = os.getenv("API_MODEL")
model = genai.GenerativeModel(MODEL_NAME)

# --- 2. ãƒšãƒ¼ã‚¸è¨­å®š & CSS ---
st.set_page_config(page_title="My AI Team", page_icon="ğŸ¤–", layout="wide")

st.markdown("""
<style>
@keyframes breathe {
    0% { transform: scale(0.98); }
    50% { transform: scale(1.02); }
    100% { transform: scale(0.98); }
}
[data-testid="stImage"] img {
    animation: breathe 3s infinite ease-in-out;
    border-radius: 10px;
    box-shadow: 0 4px 6px rgba(0, 0, 0, 0.1);
}
.breathing-icon {
    display: inline-block;
    animation: breathe 3s infinite ease-in-out;
    font-size: 5rem;
    margin-bottom: 20px;
}
</style>
""", unsafe_allow_html=True)

# --- 3. è¨˜æ†¶ ---
if "histories" not in st.session_state:
    st.session_state["histories"] = {name: [] for name in CHARACTERS.keys()}

# --- 4. ã‚µã‚¤ãƒ‰ãƒãƒ¼ ---
st.sidebar.title("ğŸ‘¥ ãƒ¡ãƒ³ãƒãƒ¼æŒ‡å")
selected_name = st.sidebar.radio("æ‹…å½“è€…ã‚’é¸æŠ:", list(CHARACTERS.keys()))

current_char = CHARACTERS[selected_name]
current_history = st.session_state["histories"][selected_name]
char_index = list(CHARACTERS.keys()).index(selected_name) # IDç”¨

st.sidebar.divider()
st.sidebar.subheader("âš™ï¸ Mode Select")
is_analysis_mode = st.sidebar.toggle("ğŸ“Š ãƒ‡ãƒ¼ã‚¿åˆ†æãƒ¢ãƒ¼ãƒ‰", value=False)

uploaded_image = None
uploaded_csv = None

if is_analysis_mode:
    st.sidebar.info("åˆ†æãƒ¢ãƒ¼ãƒ‰èµ·å‹•ä¸­...")
    uploaded_csv = st.sidebar.file_uploader("CSVãƒ•ã‚¡ã‚¤ãƒ«", type=["csv"])
else:
    st.sidebar.write("ğŸ“¸ ç”»åƒã‚’è¦‹ã›ã‚‹")
    uploaded_image = st.sidebar.file_uploader("å†™çœŸã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰", type=["png", "jpg", "jpeg"], label_visibility="collapsed")

with st.sidebar:
    st.divider()
    st.write("ğŸ–¼ï¸ ãƒ‘ãƒ¼ãƒˆãƒŠãƒ¼")
    if current_char['icon'].endswith(('.png', '.jpg', '.jpeg', '.gif')):
        st.image(current_char['icon'], caption=f"{selected_name}", use_container_width=True)
    else:
        st.markdown(f"<div style='font-size: 80px; text-align: center;'>{current_char['icon']}</div>", unsafe_allow_html=True)
    
    if st.button("ğŸ—‘ï¸ ä¼šè©±ã‚’ã‚¯ãƒªã‚¢"):
        st.session_state["histories"][selected_name] = []
        st.rerun()

# --- 5. ãƒ¡ã‚¤ãƒ³ç”»é¢ ---
col1, col2 = st.columns([1, 8])
with col1:
    if current_char['icon'].endswith(('.png', '.jpg', '.jpeg', '.gif')):
        st.image(current_char['icon'], use_container_width=True)
    else:
        st.markdown(f"<div class='breathing-icon'>{current_char['icon']}</div>", unsafe_allow_html=True)

with col2:
    if is_analysis_mode:
        st.title(f"{selected_name} [Analysis Mode ğŸ“Š]")
    else:
        st.title(f"{selected_name}")
    st.caption(f"æ€§æ ¼: {current_char['style']}")

st.divider()

# --- 6. ä¼šè©±ãƒ­ã‚° ---
for msg in current_history:
    if msg["role"] == "user":
        st.chat_message("user").write(msg["content"])
    else:
        st.chat_message("assistant", avatar=current_char['icon']).write(msg["content"])

# --- 7. å…¥åŠ›ã‚¨ãƒªã‚¢ (ãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«ç‰ˆ) ---
st.write("---") 

col_mic, col_spacer = st.columns([2, 8])
audio_data = None # éŒ²éŸ³ãƒ‡ãƒ¼ã‚¿ãŒå…¥ã‚‹å¤‰æ•°

with col_mic:
    st.write("ğŸ™ï¸ éŸ³å£°å…¥åŠ› (Geminiç›´é€š):")
    # å˜ç´”ãªéŒ²éŸ³ãƒœã‚¿ãƒ³ (mic_recorder) ã«æˆ»ã—ã¾ã—ãŸ
    # ã“ã‚Œãªã‚‰å‹æ‰‹ãªç¿»è¨³ã‚’ã›ãšã€ç”Ÿã®éŸ³å£°ãƒ‡ãƒ¼ã‚¿ã‚’è¿”ã—ã¦ãã‚Œã¾ã™
    audio_data = mic_recorder(
        start_prompt="â— éŒ²éŸ³ (ON)",
        stop_prompt="â–  åœæ­¢ (OFF)",
        key=f'MIC_{char_index}'
    )

text_input = st.chat_input(f"{selected_name} ã«ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’é€ã‚‹...")

# --- 8. é€ä¿¡å‡¦ç† ---
if audio_data or text_input:
    # A. ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®å…¥åŠ›ã‚’ç¢ºå®šã•ã›ã‚‹
    user_content_for_gemini = []
    display_text = ""

    if audio_data:
        # éŸ³å£°ãŒã‚ã‚‹å ´åˆ: Geminiã«ã€Œã“ã®éŸ³ã‚’èã„ã¦ã€ã¨é ¼ã‚€
        display_text = "ğŸ¤ (éŸ³å£°ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’é€ä¿¡ã—ã¾ã—ãŸ)"
        # éŸ³å£°ãƒ‡ãƒ¼ã‚¿ã‚’Geminiç”¨ã®å½¢å¼ã«
        user_content_for_gemini = [
            "ä»¥ä¸‹ã®éŸ³å£°ã‚’ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®ç™ºè¨€ã¨ã—ã¦èãå–ã‚Šã€ãã®å†…å®¹ã«å¯¾ã—ã¦è¿”äº‹ã‚’ã—ã¦ãã ã•ã„ã€‚",
            {"mime_type": "audio/webm", "data": audio_data['bytes']}
        ]
    elif text_input:
        # ãƒ†ã‚­ã‚¹ãƒˆã®å ´åˆ
        display_text = text_input
        user_content_for_gemini = ["ãƒ¦ãƒ¼ã‚¶ãƒ¼: " + text_input]

    # B. ç”»é¢ã«è¡¨ç¤º
    st.chat_message("user").write(display_text)
    st.session_state["histories"][selected_name].append({"role": "user", "content": display_text})

    # C. ä»–ã®æ·»ä»˜ãƒ•ã‚¡ã‚¤ãƒ« (ç”»åƒ/CSV) ã‚’è¿½åŠ 
    base_prompt = current_char['prompt']
    final_prompt_list = [base_prompt] # ã¾ãšã‚·ã‚¹ãƒ†ãƒ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ

    # æ·»ä»˜ãƒ•ã‚¡ã‚¤ãƒ«å‡¦ç†
    if is_analysis_mode:
        final_prompt_list.append("\nã€ãƒ¢ãƒ¼ãƒ‰: ãƒ‡ãƒ¼ã‚¿åˆ†æã€‘å°‚é–€å®¶ã¨ã—ã¦æŒ¯ã‚‹èˆã£ã¦ãã ã•ã„ã€‚")
        if uploaded_csv:
            try:
                import pandas as pd
                df = pd.read_csv(uploaded_csv)
                csv_head = df.head().to_markdown()
                final_prompt_list.append(f"ã€CSVãƒ‡ãƒ¼ã‚¿(å…ˆé ­5è¡Œ)ã€‘\n{csv_head}")
            except: pass
    elif not is_analysis_mode and uploaded_image:
        img = Image.open(uploaded_image)
        final_prompt_list.append(img)
    
    # æœ€å¾Œã«ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®å…¥åŠ›(éŸ³å£°orãƒ†ã‚­ã‚¹ãƒˆ)ã‚’çµåˆ
    final_prompt_list.extend(user_content_for_gemini)

    # D. Geminiå®Ÿè¡Œ
    with st.spinner(f"{selected_name} ãŒè€ƒãˆä¸­..."):
        try:
            response = model.generate_content(final_prompt_list)
            ai_msg = response.text
        except Exception as e:
            ai_msg = f"ã‚¨ãƒ©ãƒ¼: {e}"

    # E. çµæœè¡¨ç¤º & å±¥æ­´ä¿å­˜
    st.chat_message("assistant", avatar=current_char['icon']).write(ai_msg)
    st.session_state["histories"][selected_name].append({"role": "assistant", "content": ai_msg})

    # F. éŸ³å£°å†ç”Ÿ (VOICEVOX)
    def generate_voice(text, speaker_id=2):
        try:
            res1 = requests.post("http://127.0.0.1:50021/audio_query", params={"text": text, "speaker": speaker_id})
            if res1.status_code != 200: return None
            query = res1.json()
            res2 = requests.post("http://127.0.0.1:50021/synthesis", json=query, params={"speaker": speaker_id})
            return res2.content
        except: return None

    audio_bytes = generate_voice(ai_msg, speaker_id=2)
    if audio_bytes:
        st.audio(audio_bytes, format="audio/wav", autoplay=True)