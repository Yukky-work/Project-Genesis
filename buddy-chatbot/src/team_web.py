import os
import requests # VOICEVOXç”¨
import streamlit as st
import google.generativeai as genai
from PIL import Image
from dotenv import load_dotenv

# ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿
from characters import DATA as CHARACTERS

# --- 1. è¨­å®š ---
load_dotenv()
API_KEY = os.getenv("GEMINI_API_KEY")
genai.configure(api_key=API_KEY)
model = genai.GenerativeModel("gemini-2.5-flash")

# --- 2. ãƒšãƒ¼ã‚¸è¨­å®š ---
st.set_page_config(page_title="My AI Team", page_icon="ğŸ¤–", layout="wide")

# --- 3. è¨˜æ†¶ã®åˆæœŸåŒ– ---
if "histories" not in st.session_state:
    st.session_state["histories"] = {name: [] for name in CHARACTERS.keys()}

# --- 4. ã‚µã‚¤ãƒ‰ãƒãƒ¼ ---
st.sidebar.title("ğŸ‘¥ ãƒ¡ãƒ³ãƒãƒ¼æŒ‡å")
selected_name = st.sidebar.radio("æ‹…å½“è€…ã‚’é¸æŠ:", list(CHARACTERS.keys()))

current_char = CHARACTERS[selected_name]
current_history = st.session_state["histories"][selected_name]

st.sidebar.divider()
st.sidebar.write("ğŸ“¸ ç”»åƒã‚’è¦‹ã›ã‚‹")
uploaded_file = st.sidebar.file_uploader("å†™çœŸã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰", type=["png", "jpg", "jpeg"], label_visibility="collapsed")

if st.sidebar.button("ğŸ—‘ï¸ ã“ã®ãƒãƒ£ãƒƒãƒˆã‚’ã‚¯ãƒªã‚¢"):
    st.session_state["histories"][selected_name] = []
    st.rerun()

# --- 5. ãƒ¡ã‚¤ãƒ³ç”»é¢ ---
col1, col2 = st.columns([1, 8])
with col1:
    st.title(current_char['icon'])
with col2:
    st.title(f"{selected_name}")
    st.caption(f"æ€§æ ¼: {current_char['style']}")

st.divider()

# --- 6. ä¼šè©±ãƒ­ã‚°è¡¨ç¤º ---
for msg in current_history:
    if msg["role"] == "user":
        st.chat_message("user").write(msg["content"])
    else:
        st.chat_message("assistant", avatar=current_char['icon']).write(msg["content"])

# --- 7. ç”»åƒãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼ ---
image_data = None
if uploaded_file:
    image_data = Image.open(uploaded_file)
    st.sidebar.image(image_data, caption="è§£æå¯¾è±¡ã®ç”»åƒ", use_container_width=True)

# --- 8. éŸ³å£°åˆæˆé–¢æ•° (VOICEVOX) ---
# â€» ã“ã“ã‚’è¿½åŠ ãƒ»ä¿®æ­£ï¼
def generate_voice(text, speaker_id=2): # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã¯å››å›½ã‚ãŸã‚“(ID:2)
    base_url = "http://127.0.0.1:50021"
    try:
        params = {"text": text, "speaker": speaker_id}
        query_res = requests.post(f"{base_url}/audio_query", params=params)
        query_json = query_res.json()
        
        synthesis_params = {"speaker": speaker_id}
        voice_res = requests.post(f"{base_url}/synthesis", json=query_json, params=synthesis_params)
        
        return voice_res.content # ãƒã‚¤ãƒŠãƒªãƒ‡ãƒ¼ã‚¿ã‚’è¿”ã™
    except Exception:
        return None

# --- 9. å…¥åŠ›ã¨å®Ÿè¡Œ ---
if prompt := st.chat_input(f"{selected_name} ã«ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’é€ã‚‹..."):
    # ãƒ¦ãƒ¼ã‚¶ãƒ¼è¡¨ç¤º
    st.chat_message("user").write(prompt)
    if image_data:
        st.chat_message("user").image(image_data, width=200)
    
    st.session_state["histories"][selected_name].append({"role": "user", "content": prompt})

    # Geminiã¸é€ä¿¡
    system_prompt = current_char['prompt']
    try:
        if image_data:
            content_list = [system_prompt, "ãƒ¦ãƒ¼ã‚¶ãƒ¼: " + prompt, image_data]
            response = model.generate_content(content_list)
        else:
            full_prompt = f"{system_prompt}\n\nãƒ¦ãƒ¼ã‚¶ãƒ¼: {prompt}"
            response = model.generate_content(full_prompt)
        ai_msg = response.text
    except Exception as e:
        ai_msg = "ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸã€‚"

    # AIè¡¨ç¤º
    st.chat_message("assistant", avatar=current_char['icon']).write(ai_msg)
    st.session_state["histories"][selected_name].append({"role": "assistant", "content": ai_msg})

    # â˜… éŸ³å£°ã‚’ç”Ÿæˆã—ã¦å†ç”Ÿï¼
    # (å…¨å“¡ å››å›½ã‚ãŸã‚“ ã®å£°ã«ãªã‚Šã¾ã™ãŒã€IDã‚’å¤‰ãˆã‚Œã°ã‚­ãƒ£ãƒ©åˆ†ã‘ã‚‚å¯èƒ½ã§ã™)
    # Fuu=2(ãƒãƒ¼ãƒãƒ«), Shiori=10(ã‚ã¾ã‚ã¾), Gem Py=2(ãƒãƒ¼ãƒãƒ«) ãªã©
    # ä»Šå›ã¯ç°¡æ˜“çš„ã«å…¨å“¡ ID=2 ã¾ãŸã¯ 3(ãšã‚“ã ã‚‚ã‚“) ç­‰ã§ãƒ†ã‚¹ãƒˆã—ã¦ãã ã•ã„
    audio_bytes = generate_voice(ai_msg, speaker_id=2) 
    
    if audio_bytes:
        # autoplay=True ã§è‡ªå‹•å†ç”Ÿï¼
        st.audio(audio_bytes, format="audio/wav", autoplay=True)